{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from langchain import BasePromptTemplate, PromptTemplate\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "from langchain.chains import LLMChain\n",
    "from pydantic import Extra, Field\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun,\n",
    "    CallbackManagerForChainRun,\n",
    ")\n",
    "import json\n",
    "from datetime import datetime\n",
    "from DateConvert import Lunar\n",
    "\n",
    "class CalendarChain(Chain):\n",
    "    \"\"\"\n",
    "    An example of a custom chain.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt: BasePromptTemplate\n",
    "    \"\"\"Prompt object to use.\"\"\"\n",
    "    llm: BaseLanguageModel\n",
    "    output_key: str = \"text\"  #: :meta private:\n",
    "\n",
    "    res_chain: Optional[LLMChain] = Field(default=None, exclude=True)\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"Will be whatever keys the prompt expects.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return self.prompt.input_variables\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Will always return text key.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return [self.output_key]\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, str]:\n",
    "        prompt_value = self.prompt.format_prompt(**inputs)\n",
    "        result = self.llm.generate_prompt(\n",
    "            prompts=[prompt_value],\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "        )\n",
    "        json_str = result.generations[0][0].text\n",
    "        dstr_arr = json.loads(json_str)\n",
    "        res_prompts = []\n",
    "        for dstr in dstr_arr:\n",
    "            d = datetime.strptime(dstr, \"%Y-%m-%d %H:%M:%S\")\n",
    "            ld = Lunar(d)\n",
    "            res_prompts.append(\n",
    "                f\"{dstr}：{ld.gz_year()}年 {ld.gz_month()}月 {ld.gz_day()}日 {ld.gz_hour()}时\"\n",
    "            )\n",
    "        res = \"\\n\".join(res_prompts)\n",
    "        return {self.output_key: res}\n",
    "\n",
    "    async def _acall(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, str]:\n",
    "        # Your custom chain logic goes here\n",
    "        # This is just an example that mimics LLMChain\n",
    "        prompt_value = self.prompt.format_prompt(**inputs)\n",
    "        if run_manager:\n",
    "            await run_manager.on_text(\n",
    "                prompt_value.to_string(), color=\"green\", end=\"\\n\", verbose=self.verbose\n",
    "            )\n",
    "        result = await self.llm.agenerate_prompt(\n",
    "            [prompt_value], callbacks=run_manager.get_child() if run_manager else None\n",
    "        )\n",
    "        try:\n",
    "            json_str = result.generations[0][0].text\n",
    "            print(json_str)\n",
    "            dstr_arr = json.loads(json_str)\n",
    "            res_prompts = []\n",
    "            for dstr in dstr_arr:\n",
    "                d = datetime.strptime(dstr, \"%Y-%m-%d %H:%M:%S\")\n",
    "                ld = Lunar(d)\n",
    "                res_prompts.append(\n",
    "                    f\"{dstr}：{ld.gz_year()}年 {ld.gz_month()}月 {ld.gz_day()}日 {ld.gz_hour()}时\"\n",
    "                )\n",
    "            res = \"\\n\".join(res_prompts)\n",
    "            return {self.output_key: res}\n",
    "        except Exception as e :\n",
    "            print(e)\n",
    "            return {self.output_key: \"\"} \n",
    "\n",
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        return \"calendar_chain\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls,\n",
    "        llm: BaseLanguageModel,\n",
    "        **kwargs: Any,\n",
    "    ) -> Chain:\n",
    "        template = \"\"\"说明\n",
    "---------------------\n",
    "下面的问题可能是需要AI通过中国命理知识解决，中间包含的日期默认为公历日期。\n",
    "如果解决该问题需要将公历日期转换成为中国的农历日期，那么请生成一个json数组字符串，数组的元素是每一个公历日期。日期的格式为yyyy-MM-dd HH:mm:ss。\n",
    "\n",
    "问题\n",
    "---------------------\n",
    "{question}\n",
    "\n",
    "要求\n",
    "---------------------\n",
    "- 如果上面的问题不包含任何日期数据，请生成一个空的json数组字符串。\n",
    "- 只生成json字符串即可，不需要生成其他任何非json格式的字符。\n",
    "\n",
    "Answer\n",
    "---------------------\n",
    "\n",
    "\"\"\"\n",
    "        prompt = PromptTemplate.from_template(template=template)\n",
    "        return cls(llm=llm, prompt=prompt, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化Agent Excutor\n",
    "\n",
    "初始化一个agent excutor。excutor里包含了一agent，这个agent里只有一个search工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.utilities import GoogleSerperAPIWrapper\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "load_dotenv(dotenv_path=\"env\")\n",
    "\n",
    "search = GoogleSerperAPIWrapper()\n",
    "gpt35_1 = OpenAI(temperature=0.1)\n",
    "calendar_chain = CalendarChain.from_llm(llm=gpt35_1, verbose=True)\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"当前搜索\",\n",
    "        func=search.run,\n",
    "        description=\"\"\"\n",
    "            当您需要回答有关当前事件或世界现状的问题或者需要通过搜索进行提问时非常有用。\n",
    "            对此的输入应该是单个搜索词。\n",
    "            \"\"\",\n",
    "        coroutine=search.arun,\n",
    "    ),\n",
    "\tTool(\n",
    "        name=\"公历时间转生辰八字\",\n",
    "        func=calendar_chain.run,\n",
    "        description=\"\"\"\n",
    "            当你需要将公历日期和时间转换成生辰八字时，可以使用这个工具。\n",
    "            \"\"\",\n",
    "        coroutine=calendar_chain.arun,\n",
    "    ),\n",
    "]\n",
    "gpt35 = OpenAI(temperature=0.9)\n",
    "chat_gpt35 = ChatOpenAI(temperature=0.9)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "agent_excutor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=gpt35_1,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    agent_kwargs={\n",
    "        \"verbose\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo\n",
    "\n",
    "调用例子。运行excutor的arun或者run就可以了。`a`开头的方法都是异步方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"Input your questions:\")\n",
    "    if user_input == \":exit\":\n",
    "        break\n",
    "    else:\n",
    "        res = await agent_excutor.arun(user_input)\n",
    "        print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
