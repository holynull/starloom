{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Sequence, Optional\n",
    "from google.cloud import vision\n",
    "import io\n",
    "from PIL import Image\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "import base64\n",
    "\n",
    "\n",
    "def googleVisionAIAnalysis(\n",
    "    feature_types: Sequence,\n",
    "    path: Optional[str] = None,\n",
    "    base64Str: Optional[str] = None,\n",
    ") -> vision.AnnotateImageResponse:\n",
    "    if path is None and base64Str is None:\n",
    "        raise Exception(\"Choose one between path and base64Str\")\n",
    "    if path != None and base64Str is not None:\n",
    "        raise Exception(\"Choose one between path and base64Str\")\n",
    "    if path != None and (path.startswith(\"http://\") or path.startswith(\"https://\")):\n",
    "        # URL链接的图片\n",
    "        response = requests.get(path)\n",
    "        if response.status_code == 200:\n",
    "            content = response.content\n",
    "            display(Image(url=path))\n",
    "        else:\n",
    "            raise Exception(f\"Rquest Failed. status: {response.status_code}\")\n",
    "    elif path != None:\n",
    "        # 本地的图片\n",
    "        with io.open(path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        display(Image(filename=path))\n",
    "    if base64Str != None:\n",
    "        content = base64.b64decode(base64Str)\n",
    "        display(Image(data=content))\n",
    "\n",
    "    # 实例化一个 Vision 客户端\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.Image(content=content)\n",
    "    features = [vision.Feature(type_=feature_type) for feature_type in feature_types]\n",
    "    request = vision.AnnotateImageRequest(image=image, features=features)\n",
    "    # 调用 Vision API\n",
    "    # response = client.document_text_detection(image=image)\n",
    "    response = client.annotate_image(request=request)\n",
    "    return response\n",
    "\n",
    "\n",
    "def print_objects(response: vision.AnnotateImageResponse) -> str:\n",
    "    re = \"Objects Annotations\"\n",
    "    split_row = \"-\" * 80\n",
    "    re = \"\\n\".join([re, split_row])\n",
    "    objs = []\n",
    "    for obj in response.localized_object_annotations:\n",
    "        nvertices = obj.bounding_poly.normalized_vertices\n",
    "        s = \"|\".join(\n",
    "            [\n",
    "                f\"{obj.score:4.0%}\",\n",
    "                f\"{obj.name:15}\",\n",
    "                f\"{obj.mid:10}\",\n",
    "                \",\".join(f\"({v.x:.1f},{v.y:.1f})\" for v in nvertices),\n",
    "            ]\n",
    "        )\n",
    "        objs.append(s)\n",
    "    return re + \"\\n\" + \"\\n\".join(objs) + \"\\n\"\n",
    "\n",
    "\n",
    "def print_labels(response: vision.AnnotateImageResponse) -> str:\n",
    "    re = \"Label Annotations\"\n",
    "    split_row = \"-\" * 80\n",
    "    re = \"\\n\".join([re, split_row])\n",
    "    labels = []\n",
    "    for label in response.label_annotations:\n",
    "        s = \"|\".join(\n",
    "            [\n",
    "                f\"{label.score:4.0%}\",\n",
    "                f\"{label.description:5}\",\n",
    "            ]\n",
    "        )\n",
    "        labels.append(s)\n",
    "    return re + \"\\n\" + \"\\n\".join(labels) + \"\\n\"\n",
    "\n",
    "\n",
    "def print_text(response: vision.AnnotateImageResponse) -> str:\n",
    "    re = \"Text Annotations\"\n",
    "    split_row = \"-\" * 80\n",
    "    re = \"\\n\".join([re, split_row])\n",
    "    texts = []\n",
    "    for annotation in response.text_annotations:\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in annotation.bounding_poly.vertices]\n",
    "        s = \"Vertices:\" + \"| Vertices: \".join(\n",
    "            [\n",
    "                f\"{repr(annotation.description):42}\",\n",
    "                \",\".join(vertices),\n",
    "            ]\n",
    "        )\n",
    "        texts.append(s)\n",
    "    return re + \"\\n\" + \"\\n\".join(texts) + \"\\n\"\n",
    "\n",
    "\n",
    "def print_faces(response: vision.AnnotateImageResponse) -> str:\n",
    "    re = \"Face Annotations\"\n",
    "    split_row = \"-\" * 80\n",
    "    re = \"\\n\".join([re, split_row])\n",
    "    faces = []\n",
    "    for face_number, face in enumerate(response.face_annotations, 1):\n",
    "        vertices = \",\".join(f\"({v.x},{v.y})\" for v in face.bounding_poly.vertices)\n",
    "        s = \"\\n\".join(\n",
    "            [\n",
    "                f\"# Face {face_number} @ {vertices}\",\n",
    "                f\"Joy:     {face.joy_likelihood.name}\",\n",
    "                f\"Exposed: {face.under_exposed_likelihood.name}\",\n",
    "                f\"Blurred: {face.blurred_likelihood.name}\",\n",
    "                \"\\n\",\n",
    "            ]\n",
    "        )\n",
    "        faces.append(s)\n",
    "    return re + \"\\n\" + \"\\n\".join(faces) + \"\\n\"\n",
    "\n",
    "\n",
    "def print_landmarks(\n",
    "    response: vision.AnnotateImageResponse, min_score: float = 0.5\n",
    ") -> str:\n",
    "    re = \"Landmark Annotations\"\n",
    "    split_row = \"-\" * 80\n",
    "    re = \"\\n\".join([re, split_row])\n",
    "    landmarks = []\n",
    "    for landmark in response.landmark_annotations:\n",
    "        if landmark.score < min_score:\n",
    "            continue\n",
    "        vertices = [f\"({v.x},{v.y})\" for v in landmark.bounding_poly.vertices]\n",
    "        lat_lng = landmark.locations[0].lat_lng\n",
    "        s = \"|\".join(\n",
    "            [\n",
    "                f\"{landmark.description:18}\",\n",
    "                \",\".join(vertices),\n",
    "                f\"{lat_lng.latitude:.5f}\",\n",
    "                f\"{lat_lng.longitude:.5f}\",\n",
    "            ]\n",
    "        )\n",
    "        landmarks.append(s)\n",
    "    return re + \"\\n\" + \"\\n\".join(landmarks) + \"\\n\"\n",
    "\n",
    "\n",
    "def print_image_properties(\n",
    "    response: vision.AnnotateImageResponse, min_score: float = 0.5\n",
    ") -> str:\n",
    "    re = \"Image Properties Annotations\"\n",
    "    split_row = \"-\" * 80\n",
    "    re = \"\\n\".join([re, split_row])\n",
    "    colors = []\n",
    "    for color in response.image_properties_annotation.dominant_colors.colors:\n",
    "        s = \"\".join(\n",
    "            [\n",
    "                \"RGB(\",\n",
    "                f\"{color.color.red:.0f},\",\n",
    "                f\"{color.color.green:.0f},\",\n",
    "                f\"{color.color.blue:.0f}\",\n",
    "                f\"{')':20}\",\n",
    "                \"|\",\n",
    "                f\"Score:{color.score:4.0%}\",\n",
    "                \"|\",\n",
    "                f\"Pixel fraction:{color.pixel_fraction:4.0%}\",\n",
    "            ]\n",
    "        )\n",
    "        colors.append(s)\n",
    "    return re + \"\\n\" + \"\\n\".join(colors) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.base import Chain\n",
    "from langchain import BasePromptTemplate\n",
    "from langchain.schema.language_model import BaseLanguageModel\n",
    "from pydantic import Extra\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForChainRun,\n",
    "    CallbackManagerForChainRun,\n",
    ")\n",
    "\n",
    "\n",
    "class GoogleVisonAIChain(Chain):\n",
    "    \"\"\"\n",
    "    An example of a custom chain.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt: BasePromptTemplate\n",
    "    \"\"\"Prompt object to use.\"\"\"\n",
    "    llm: BaseLanguageModel\n",
    "    output_key: str = \"text\"  #: :meta private:\n",
    "\n",
    "    class Config:\n",
    "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
    "\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"Will be whatever keys the prompt expects.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return self.prompt.input_variables\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Will always return text key.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return [self.output_key]\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[CallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, str]:\n",
    "        prompt_value = self.prompt.format_prompt(**inputs)\n",
    "        if run_manager:\n",
    "            run_manager.on_text(\n",
    "                prompt_value.to_string(), color=\"green\", end=\"\\n\", verbose=self.verbose\n",
    "            )\n",
    "        result = self.llm.generate_prompt(\n",
    "            prompts=[prompt_value],\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "        )\n",
    "        if run_manager:\n",
    "            run_manager.on_text(\n",
    "                result.generations[0][0].text,\n",
    "                color=\"yellow\",\n",
    "                end=\"\\n\",\n",
    "                verbose=self.verbose,\n",
    "            )\n",
    "        return {self.output_key: result.generations[0][0].text}\n",
    "\n",
    "    async def _acall(\n",
    "        self,\n",
    "        inputs: Dict[str, Any],\n",
    "        run_manager: Optional[AsyncCallbackManagerForChainRun] = None,\n",
    "    ) -> Dict[str, str]:\n",
    "        prompt_value = self.prompt.format_prompt(**inputs)\n",
    "        if run_manager:\n",
    "            await run_manager.on_text(\n",
    "                prompt_value.to_string(), color=\"green\", end=\"\\n\", verbose=self.verbose\n",
    "            )\n",
    "        result = await self.llm.agenerate_prompt(\n",
    "            prompts=[prompt_value],\n",
    "            callbacks=run_manager.get_child() if run_manager else None,\n",
    "        )\n",
    "        if run_manager:\n",
    "            await run_manager.on_text(\n",
    "                result.generations[0][0].text,\n",
    "                color=\"yellow\",\n",
    "                end=\"\\n\",\n",
    "                verbose=self.verbose,\n",
    "            )\n",
    "        return {self.output_key: result.generations[0][0].text}\n",
    "\n",
    "    @property\n",
    "    def _chain_type(self) -> str:\n",
    "        return \"calendar_chain\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_llm(\n",
    "        cls,\n",
    "        llm: BaseLanguageModel,\n",
    "        **kwargs: Any,\n",
    "    ) -> Chain:\n",
    "        template = \"\"\"{vision_ai_answer}\n",
    "\n",
    "说明\n",
    "---------------------\n",
    "- 上面是一张图片经过分析后的数据。\n",
    "- 图片主题分类：风景主题、人物主题、户型图主题和其他\n",
    "- 在下面\"图片内容\"处，根据不同的主题，按照下面相应\"要求\"，用一段话描写出你看到的内容。\n",
    "\n",
    "风景主题要求\n",
    "---------------------\n",
    "- 不要使用\"标注\"和\"注释\"\n",
    "- 要求说明图片中都包含了哪些内容\n",
    "- 要求写出对图片的颜色和光线的感受\n",
    "- 要求对整体图片的背景进行分析\n",
    "- 如果图片包含有地标，要求对图片中包含的地标进行简单的介绍\n",
    "\n",
    "人物主题要求\n",
    "---------------------\n",
    "- 不要使用\"标注\"和\"注释\"\n",
    "- 要求说明图片中都包含了哪些内容\n",
    "- 要求写出对图片的颜色和光线的感受\n",
    "- 要求对整体图片的背景进行分析\n",
    "- 要求详细描写人物的面容表情\n",
    "- 要求详细描写人物的衣着\n",
    "\n",
    "户型图主题要求\n",
    "---------------------\n",
    "- 不要使用\"标注\"和\"注释\"\n",
    "- 默认向上方为北方。\n",
    "- 要求说明图片中都包含了哪些内容\n",
    "- 要求描述清楚各个房间的位置\n",
    "- 要求预测房间门的朝向。\n",
    "\n",
    "其他主题要求\n",
    "---------------------\n",
    "- 要求说明图片中都包含了哪些内容\n",
    "\n",
    "图片内容\n",
    "---------------------\n",
    "\"\"\"\n",
    "        prompt = PromptTemplate.from_template(template=template)\n",
    "        return cls(llm=llm, prompt=prompt, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export DISPLAY=:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def analysisImage(img_str: str) -> str:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv(dotenv_path=\"env\")\n",
    "    features = [\n",
    "        vision.Feature.Type.OBJECT_LOCALIZATION,\n",
    "        vision.Feature.Type.FACE_DETECTION,\n",
    "        vision.Feature.Type.LANDMARK_DETECTION,\n",
    "        vision.Feature.Type.LABEL_DETECTION,\n",
    "        vision.Feature.Type.TEXT_DETECTION,\n",
    "        vision.Feature.Type.IMAGE_PROPERTIES,\n",
    "    ]\n",
    "    import os\n",
    "\n",
    "    if img_str.startswith((\"http://\", \"https://\")):\n",
    "        response = googleVisionAIAnalysis(path=img_str, feature_types=features)\n",
    "    # 检查是否是本地文件路径\n",
    "    elif os.path.isfile(img_str):\n",
    "        response = googleVisionAIAnalysis(path=img_str, feature_types=features)\n",
    "    # 检查是否是base64\n",
    "    else:\n",
    "        try:\n",
    "            # Remove base64 image prefix if any\n",
    "            if \"base64,\" in img_str:\n",
    "                n_img_str = img_str.split(\"base64,\")[1]\n",
    "            # Check if result is url safe\n",
    "            url_safe_base64 = \"-\" in n_img_str or \"_\" in n_img_str\n",
    "            import urllib\n",
    "\n",
    "            base64_str = (\n",
    "                urllib.parse.unquote(img_str)\n",
    "                + (3 - len(urllib.parse.unquote(img_str)) % 3) * \"=\"\n",
    "            )\n",
    "            base64.b64decode(base64_str, altchars=\"+-\" if url_safe_base64 else None)\n",
    "        except Exception:\n",
    "            raise Exception(f\"img_str format error:{img_str}\")\n",
    "        response = googleVisionAIAnalysis(base64Str=n_img_str, feature_types=features)\n",
    "\n",
    "    vision_ai_answer = \"\\n\".join(\n",
    "        [\n",
    "            print_objects(response),\n",
    "            print_labels(response),\n",
    "            print_text(response),\n",
    "            print_faces(response),\n",
    "            print_landmarks(response),\n",
    "            print_image_properties(response),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    # chat_gpt = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-16k\", verbose=True)\n",
    "    chat_gpt = ChatOpenAI(temperature=0, model=\"gpt-4\", verbose=True)\n",
    "    chain = GoogleVisonAIChain.from_llm(llm=chat_gpt,verbose=True)\n",
    "    return await chain.arun(vision_ai_answer=vision_ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "await analysisImage(img_str=input(\"Input image path or url or base64 string: \"))"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
